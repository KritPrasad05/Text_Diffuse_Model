{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95192613-f7d8-4e7f-afab-b6374a28ea8c",
   "metadata": {},
   "source": [
    "# Text Generation using Diffusion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e301b6-5f07-4467-8219-ab8b086e1620",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbaba19d-de96-4d18-9a76-26d8853d9917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kritr\\Downloads\\INTERNSHIP\\DevifyX\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857262d-5f05-437d-9ad3-ed23a7154a52",
   "metadata": {},
   "source": [
    "## Setting up the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9092fc74-eb83-4c54-8b01-cf90f9a4e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f178e9-f7c1-4d41-8f99-f89530081553",
   "metadata": {},
   "source": [
    "## Loading the Dataset(wikitext 2)\n",
    "\n",
    "- Dataset Summary\n",
    "<p>\n",
    "  \n",
    "        The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike License.\n",
    "\n",
    "        The WikiText dataset also features a far larger vocabulary and retains the original case, punctuation and numbers - all of which are removed in PTB. As it is composed of full articles, the dataset is well suited for models that can take advantage of long term dependencies.\n",
    "\n",
    "        Each subset comes in two different variants:\n",
    "\n",
    "            1 Raw (for character level work) contain the raw tokens, before the addition of the (unknown) tokens.\n",
    "            2 Non-raw (for word level work) contain only the tokens in their vocabulary (wiki.train.tokens, wiki.valid.tokens, and wiki.test.tokens). The out-of-vocabulary tokens have been replaced with the the token.\n",
    "\n",
    "</p>\n",
    "\n",
    "<details>\n",
    "<summary>Dataset Structure</summary>\n",
    "\n",
    "    wikitext-2-raw-v1\n",
    "        - Size of downloaded dataset files: 4.72 MB\n",
    "        - Size of the generated dataset: 13.54 MB\n",
    "        - Total amount of disk used: 18.26 MB\n",
    "\n",
    "    An example of 'train' looks as follows.\n",
    "\n",
    "    This example was too long and was cropped:\n",
    "<code>\n",
    "\n",
    "{\n",
    "    \"text\": \"\\\" The Sinclair Scientific Programmable was introduced in 1975 , with the same case as the Sinclair Oxford . It was larger than t...\"\n",
    "}\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314658b2-b02b-415a-93c5-bfcc3a0068d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4358\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 36718\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3760\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load WikiText-2 (or switch to 'wikitext' and subset='wikitext-103-raw-v1' for larger variant)\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54bfbbf-d0c2-4f2b-b2a7-0c114ea9eebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36718"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the size of the dataset\n",
    "len(dataset['train']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32fb46-2e1d-4c8d-a129-0c0c4ae7f4bf",
   "metadata": {},
   "source": [
    "## Creating a Custom Dataset \n",
    "\n",
    "We're going to create a Custom dataset function by sub-classing the pytorch `torch.utils.data.Dataset()` class. This is done so that we can load in the dataset accordingly as per the pytorch library needs. \n",
    "\n",
    "The main reason to subclass the `Dataset()` class is for PyTorchâ€™s `DataLoader` can fetch small \"batches\" of data from it while training your model â€” like a vending machine that gives you exactly what you ask for, in bite-sized pieces.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e28cebe-ae6a-4cd9-8e06-77d75b339db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, vocab=None, seq_len=32):\n",
    "        self.seq_len = seq_len\n",
    "        self.tokens = [token for line in texts for token in line.split()]\n",
    "        self.vocab = vocab or self.build_vocab(self.tokens)\n",
    "        self.token_ids = [self.vocab['stoi'].get(token, self.vocab['stoi']['<unk>']) for token in self.tokens]\n",
    "\n",
    "    def build_vocab(self, tokens):\n",
    "        vocab = sorted(set(tokens))\n",
    "        stoi = {token: i+4 for i, token in enumerate(vocab)}\n",
    "        stoi.update({'<pad>': 0, '<unk>': 1, '<bos>': 2, '<eos>': 3})\n",
    "        itos = {i: token for token, i in stoi.items()}\n",
    "        return {'stoi': stoi, 'itos': itos}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_ids) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.token_ids[idx:idx+self.seq_len]\n",
    "        return torch.tensor(chunk, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c11dcf-8423-4898-af59-6b6ae6f5caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, vocab = None, seq_len = 32):\n",
    "        self.seq_len = seq_len\n",
    "        self.tokens = [token for line in texts for token in line.split()]\n",
    "        self.vocab = vocab or self.build_vocab(self.tokens)\n",
    "        self.token_ids = [self.vocab['stoi'].get(token, self.vocab['stoi']['unk']) for token in self.tokens]\n",
    "\n",
    "    def build_vocab(self, tokens):\n",
    "        vocab = sorted(set(tokens)) #To extract unique words out of the datasets \n",
    "        stoi = {token : ids+4 for ids, token in enumerate(vocab)}\n",
    "        stoi.update({'<pad>':0,'<unk>':1, '<bos>': 2, '<eos>': 3})\n",
    "        itos = {ids: token for token, ids in stoi.items()}\n",
    "        return {'stoi' : stoi, 'itos' : itos}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_ids) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunks = self.token_ids[idx:idx+self.seq_len]\n",
    "        return torch.tensor(chunk, dtype = torch.long)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8282eee-ebf1-4875-9eca-5ba8acccb541",
   "metadata": {},
   "source": [
    "## Creating the `data.py` pakage in the data folder\n",
    "\n",
    "Now we'll modulate things and shift eh above code to `data.py` so that we can increase modularity and reusabilty of code.  \n",
    "\n",
    "### data.py\n",
    "\n",
    "It will consist of:\n",
    "\n",
    "- `get_dataset()`: To get the desired dataset and load it into the working file using the pytorch built-in function `load_dataset()` function and then it returns list of non-empty text strings.\n",
    "\n",
    "- `TextDataset()`: This is a class method created to tokenise the text in the given data and converts raw text to tokenIDs and visa versa providing sequential length of the dataset for pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5497a57a-ea40-4732-9cf4-19aa048a4be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kritr\\Downloads\\INTERNSHIP\\DevifyX\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32])\n",
      "tensor([[    5,   271,     3,     2, 26810,  1755,  5154,  1616,   213, 65913,\n",
      "         75027, 54249, 49676, 72532, 36726, 34517, 18959, 55628, 16694,   180,\n",
      "         69744, 62863,   271, 35906, 56975, 44584, 52341, 41081,  1848, 47725,\n",
      "         40112, 72532],\n",
      "        [ 8394, 38663, 61579, 72169,  8332, 22219, 18796, 41081, 72169, 61884,\n",
      "         41953,  8394, 15326, 61579, 72169, 28025, 18796,   271, 35866, 68492,\n",
      "         41953,  8394, 38663, 55872, 13419, 63106,   213, 39889, 36560,   213,\n",
      "          7726, 20604],\n",
      "        [17832, 17522, 75027, 66694, 41679, 72169, 45255, 61478, 17832,   213,\n",
      "         75468, 72169, 61817, 62671, 72164, 72991, 72365, 72169, 45255, 42754,\n",
      "         66462, 72169, 26754, 17832, 17522,   271, 18536,  1547,   213, 49731,\n",
      "         72169, 51254],\n",
      "        [58800,  2975, 58663,   271,     3,     2, 35866, 12970, 44603, 41614,\n",
      "             5, 61478, 73942, 47655, 41081, 42053,     5,   271,  4809, 54861,\n",
      "         54456, 47656, 72169, 44603, 55792, 72169, 65489, 61478, 57742,  2422,\n",
      "         72532, 57742]])\n"
     ]
    }
   ],
   "source": [
    "from data.data import TextDataset, get_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "texts = get_dataset()  # Load WikiText-2\n",
    "dataset = TextDataset(texts, seq_len=32)  # Create dataset\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)  # Training batches\n",
    "\n",
    "# Test\n",
    "for batch in loader:\n",
    "    print(batch.shape)\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbfe580e-8106-4bd6-9807-fe19f792a940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2970, 37532,  9281, 18264,  2970,     3,     2, 32722, 60992, 37532,\n",
       "          1888,  2964, 37307,  9281,   209, 19312,  2964, 76516,   213, 58257,\n",
       "           271, 37532, 61478, 72169,  5953,  1888,   210,   213, 45876, 66058,\n",
       "         72532, 41757]),\n",
       " 2099412,\n",
       " 'tensor([[42754,  1297, 55851,   209,  2189, 59928,   210, 75338, 41081, 54459,\\n         39889, 63395, 61478,  1952, 76353,  2005, 55851,   209,  2757, 76353,\\n          2850, 59928,   210,   271,     3,     2,  2970,  2970,  2970, 18536,\\n          2975, 52301],\\n        [72462, 68654, 57890,   213, 72169,   640, 50715, 68654, 45516,  2975,\\n         55106, 58663, 54679, 31691,   180, 58409,  2975, 68495, 38577, 37332,\\n         41073,   213, 39889, 58962, 72164, 75618, 57747, 42625, 62609, 44005,\\n         54679, 66571],\\n        [75428,   213, 72251, 60319, 61579, 52547, 39889, 66400, 75468, 72169,\\n         19379, 55792, 72169, 14269,   271,     3,     2, 35866,  7676, 66971,\\n         72532, 72169, 11420,  8741, 52547, 15191,  2424, 61579, 19761,   877,\\n           213,  1566],\\n        [52340, 41023, 56890, 59692, 55792, 72169, 60413, 61478, 21808,   213,\\n         57374,  1848, 59705, 41081, 72977,  1660, 61886, 73673,   271, 21317,\\n         72169, 59197, 72532, 49582, 41023, 50837, 68586,   213, 72169, 42113,\\n         75208, 52564]])')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(idx = 1), dataset.__len__(), f\"{next(iter(loader))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f122398-86d7-43c3-b92f-bbbb644f847c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ðŸ”§ Whatâ€™s Coming Up Next?\n",
    "Once your forward diffusion process is working, youâ€™ll move to:\n",
    "\n",
    "ðŸ”œ Step 2B: Build transformer.py or denoiser.py (inside model/)\n",
    "This will be your denoising model â€” a Transformer that learns to reverse the noise\n",
    "\n",
    "Takes x_t and timestep t as input\n",
    "\n",
    "Outputs predicted noise (epsilon) or clean embedding (x_0)\n",
    "\n",
    "ðŸ”œ Step 2C: Build train.py\n",
    "Sample a batch\n",
    "\n",
    "Embed the tokens\n",
    "\n",
    "Add noise with q_sample\n",
    "\n",
    "Feed into the denoiser model\n",
    "\n",
    "Compute loss: MSE between predicted noise and real noise\n",
    "\n",
    "Backprop + update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7664dd7b-6508-4036-8c41-20ebd19e0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionScheduler:\n",
    "    def __init__(self, timesteps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "        # Linearly spaced noise schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        \"\"\"\n",
    "        Adds noise to the input x_start at timestep t using the forward diffusion process.\n",
    "\n",
    "        x_start: [batch_size, seq_len, embed_dim]\n",
    "        t:       [batch_size]  (each example gets a different t)\n",
    "        noise:   optional, usually sampled as Gaussian\n",
    "\n",
    "        Returns:\n",
    "        - x_t: noised version of x_start\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "\n",
    "        # Grab sqrt(alpha_bar_t) and sqrt(1 - alpha_bar_t)\n",
    "        sqrt_alpha_bar = self.alpha_bars[t].sqrt().unsqueeze(-1).unsqueeze(-1)\n",
    "        sqrt_one_minus = (1. - self.alpha_bars[t]).sqrt().unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        return sqrt_alpha_bar * x_start + sqrt_one_minus * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06f6689-0ab2-42ec-b265-d671f1c296d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "from model.diffusion import DiffusionScheduler\n",
    "import torch\n",
    "\n",
    "scheduler = DiffusionScheduler(timesteps=1000)\n",
    "\n",
    "# Let's say we have a batch of 4 sequences of 32 tokens, each embedded into 128-dim vectors\n",
    "dummy_x0 = torch.randn(4, 32, 128)\n",
    "\n",
    "# Pick random timesteps per example\n",
    "t = torch.randint(0, 1000, (4,))\n",
    "\n",
    "# Apply forward diffusion\n",
    "noised = scheduler.q_sample(dummy_x0, t)\n",
    "\n",
    "print(noised.shape)  # should be [4, 32, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d935ee01-e39d-4657-821c-28091d52e913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0678, -1.3845,  0.0851,  ..., -1.2500,  1.8699,  1.1276],\n",
       "         [ 0.8173,  0.2286, -0.0371,  ...,  1.0060,  0.5737,  1.4500],\n",
       "         [-0.4166, -0.8074, -0.9974,  ...,  1.8061, -0.8163, -0.3107],\n",
       "         ...,\n",
       "         [-0.6591,  1.6974,  0.8974,  ..., -0.0743, -0.4791,  1.0851],\n",
       "         [ 0.0242,  0.4518,  0.5199,  ...,  0.1125, -1.4947,  1.0043],\n",
       "         [ 1.7052,  0.1211, -0.9793,  ..., -0.0702,  2.0426, -0.0462]],\n",
       "\n",
       "        [[-0.7610,  0.6079, -1.1344,  ..., -0.6155, -0.2053,  2.1369],\n",
       "         [-0.4764, -0.8814, -1.8197,  ..., -0.0885,  0.7705, -1.5596],\n",
       "         [ 0.1469, -0.8987,  0.1743,  ...,  1.5399,  1.0794,  0.8385],\n",
       "         ...,\n",
       "         [ 2.3168, -0.9489,  0.9145,  ...,  0.8214, -0.4625,  1.2840],\n",
       "         [-0.2112,  0.1706,  0.2229,  ...,  0.4296, -1.8151, -0.3240],\n",
       "         [-0.6965, -2.7814,  2.0372,  ...,  2.0681,  1.7682,  0.8996]],\n",
       "\n",
       "        [[ 0.9564,  0.6396, -0.9033,  ..., -0.7909, -0.2044,  1.6278],\n",
       "         [-1.0492, -2.0203, -0.1611,  ..., -2.1430, -0.1944, -1.5165],\n",
       "         [-0.2399, -0.7090, -1.0587,  ..., -1.1626,  0.8093, -0.2328],\n",
       "         ...,\n",
       "         [ 0.5082, -0.4912, -1.6559,  ...,  1.9804, -0.7927, -1.9468],\n",
       "         [ 1.0178, -0.6755,  0.1456,  ...,  1.1196, -1.9212,  0.0316],\n",
       "         [ 1.7276,  0.7514, -0.0503,  ...,  1.2029,  0.7572, -1.1675]],\n",
       "\n",
       "        [[-0.4641,  1.6256,  0.6833,  ..., -1.3795, -0.5560,  0.8254],\n",
       "         [-0.4563, -0.8502,  1.6340,  ..., -0.2104,  0.2708,  0.4584],\n",
       "         [ 1.4032,  3.0310,  0.7797,  ..., -0.5323,  1.3677, -0.2351],\n",
       "         ...,\n",
       "         [-0.1563,  0.3222, -0.6256,  ..., -0.3039, -0.5315, -0.7187],\n",
       "         [ 0.4136, -1.0692, -0.4633,  ..., -0.0232,  0.5854, -0.4762],\n",
       "         [ 1.4905,  0.4862,  1.3690,  ...,  1.0458,  0.8014,  0.5826]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ee97f-0f26-4fea-adac-3924b32c06c9",
   "metadata": {},
   "source": [
    "### Testing Diffusior and transformer model\n",
    "\n",
    "We've created the diffusion model to diffuse noise into the text we have build the `denoiser.py` and to predict and learn from the noisy text we've built the `transformer.py` file in the `DevifyX/model` directory.\n",
    "\n",
    "<H4><code>diffuse.py</code></H4>\n",
    "\n",
    "- It creates and add random noise using `q_sample()` function which takes in 3 positional arguments:\n",
    "- Inputs:\n",
    "  -   x_start: [batch_size, seq_len, embed_dim]\n",
    "  -   t:       [batch_size]  (each example gets a different t)\n",
    "  -   noise:   optional, usually sampled as Gaussian\n",
    "- Output:\n",
    "    - It outputs noised vectors or accuretly speaking emebeddings to make train and predict noise.\n",
    "\n",
    "<H4>`denoiser.py`</H4>\n",
    "\n",
    "- It firstly creates the embedding vector which is passed into the `diffusion.py` to add noise, this is achive through using the pre-built `nn.Embedding()` function in pytorch.\n",
    "- `denoiser.py`  is also used to predict those noise and there timestamp as noises are added.\n",
    "-  Inputs:\n",
    "    - x: Tensor of shape (B, T, E) â†’ batch of noised embeddings\n",
    "    - t: Tensor of shape (B,) â†’ timestep values for each example\n",
    "\n",
    "- Output:\n",
    "    - A tensor of shape (B, T, E), where each vector is the predicted noise for the corresponding token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105de5fe-8762-4833-856e-819bcd6242f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kritr\\Downloads\\INTERNSHIP\\DevifyX\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data.data import TextDataset, get_dataset\n",
    "from model.denoiser import DenoiseTransformer\n",
    "from model.diffusion import DiffusionScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44a052c-d40e-4c74-b012-034ad8da991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = get_dataset()\n",
    "dataset = TextDataset(texts, seq_len=32, use_saved_vocab=True)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d5a921-6cdc-4886-8b65-f08ffa0d251a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76620"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(dataset.vocab['stoi'])\n",
    "denoiser = DenoiseTransformer(vocab_size=vocab_size, embed_dim=128)\n",
    "scheduler = DiffusionScheduler(timesteps=1000)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85335ea6-1063-491f-ae9f-fed7e8771b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76620"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.vocab['itos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ea05ae-f80f-467a-910c-96c728353651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID Batch Shape: torch.Size([2, 32])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))  # Shape: [B, T] â†’ e.g., [2, 32]\n",
    "print(f\"Token ID Batch Shape: {batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897f5dc8-679a-4736-8565-73b1fe6f0e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Shape: torch.Size([2, 32, 128])\n",
      "Timestep Tensor: tensor([225, 937])\n",
      "Noised Embedding Shape: torch.Size([2, 32, 128])\n",
      "Predicted Noise Shape: torch.Size([2, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Embed tokens\n",
    "x_embed = denoiser.embed(batch)  # Shape: [B, T, E]\n",
    "print(f\"Embedded Shape: {x_embed.shape}\")\n",
    "\n",
    "# Step 2: Random timesteps for batch\n",
    "t = torch.randint(0, 1000, (batch.shape[0],))\n",
    "print(f\"Timestep Tensor: {t}\")\n",
    "\n",
    "# Step 3: Add noise using diffusion forward process\n",
    "x_noised = scheduler.q_sample(x_embed, t)\n",
    "print(f\"Noised Embedding Shape: {x_noised.shape}\")\n",
    "\n",
    "# Step 4: Pass through DenoiseTransformer to predict noise\n",
    "predicted_noise = denoiser(x_noised, t)\n",
    "print(f\"Predicted Noise Shape: {predicted_noise.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e719313a-bd44-45da-8de7-f496e4c0196f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2812,  0.1291,  0.7951,  ..., -0.7136,  0.7900, -0.3231],\n",
       "         [ 0.1068,  0.0795,  0.1732,  ..., -0.0929, -0.7796,  0.0147],\n",
       "         [ 0.1584, -0.2867,  0.4291,  ..., -0.6167, -0.1353, -0.2176],\n",
       "         ...,\n",
       "         [ 0.1966, -0.8382,  0.5694,  ..., -0.4986,  0.0496, -0.8049],\n",
       "         [-0.2742, -0.0665,  0.8035,  ..., -0.1824, -0.2967,  0.4316],\n",
       "         [-1.0752, -0.1389,  0.2681,  ..., -0.4057, -0.1762,  0.1605]],\n",
       "\n",
       "        [[ 0.0506, -0.1451, -1.0272,  ...,  0.0197,  0.6920,  0.5740],\n",
       "         [-0.6091, -0.5157, -0.8021,  ...,  0.7726, -0.6679,  1.0073],\n",
       "         [ 0.1321, -0.5641, -0.3232,  ..., -0.1548,  0.2380,  0.7189],\n",
       "         ...,\n",
       "         [-0.3393,  0.0707, -0.1923,  ..., -0.8481,  0.3441, -0.0971],\n",
       "         [-0.2560, -0.6433, -0.1511,  ..., -0.1240, -0.4294,  1.1825],\n",
       "         [-0.5841, -0.8877, -1.0142,  ...,  0.2352,  0.0089,  0.7606]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8df001-cbd0-422a-b69f-e046f71102cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b55366-d080-4bfb-aabc-52360008da75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946b0af-79ed-43cf-be72-e967b9df47c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e11b1-096c-4806-9d59-35df9e817178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36629555-dbfd-4043-adfc-37375ea1f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d18dd-24cb-41ca-8e65-cffd4d8f885f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1492fc-2c5c-40f6-83c8-2b81daba3670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DevifyX)",
   "language": "python",
   "name": "devifyx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
